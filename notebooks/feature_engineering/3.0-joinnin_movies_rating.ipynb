{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Gestionar las rutas\n",
    "import utils.paths as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = path.make_dir_function(\"data\")\n",
    "data_proc_dir = raw_data_dir(\"interim\")\n",
    "parquet_files = data_proc_dir.glob(\"*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios de los datasets\n",
    "parquet_df = {}\n",
    "for parquet_file in parquet_files:\n",
    "    parquet_df[f\"{parquet_file.name.split('.')[0]}\"] = pd.read_parquet(parquet_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['userId', 'score', 'timestamp', 'movieId'], dtype='object'),\n",
       " (11013823, 4))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_df[\"ratings_v1\"].columns , parquet_df[\"ratings_v1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
       "        'release_year', 'rating', 'duration', 'duration_int', 'duration_type',\n",
       "        'listed_in', 'description'],\n",
       "       dtype='object'),\n",
       " (22998, 14))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_df[\"movies_v1\"].columns, parquet_df[\"movies_v1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminaremos la columna duration del dataset de ratings\n",
    "parquet_df[\"movies_v1\"] = parquet_df[\"movies_v1\"].drop(\"duration\", axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset para el desarrllo de la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_movies_ratings_api(df_list):\n",
    "    # Union del tipo left de movies_v1 con ratings_v1\n",
    "    df_merged = pd.merge(df_list[\"movies_v1\"], df_list[\"ratings_v1\"][['score', 'movieId']].groupby(\"movieId\").mean().round(1), left_on=\"show_id\", right_on=\"movieId\", how=\"left\")\n",
    "    # Resetear la numeracion de los índices\n",
    "    df_merged = df_merged.reset_index(drop=True)\n",
    "    # Eliminar el movieId\n",
    "    # df_merged = df_merged.drop(columns=\"movieId\", axis=1)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_df = merge_movies_ratings_api(parquet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportación de la data\n",
    "def save_as_parquet_api_data(df,file_name):\n",
    "    data_proc_dir = path.make_dir_function(\"dataset\")\n",
    "    file_path = data_proc_dir(file_name)\n",
    "    df.to_parquet(f\"{file_path}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando la data que será consumido por la API\n",
    "save_as_parquet_api_data(api_df,\"api_data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset para el Sistema de recomendación basado el filtro colaborativo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos la tripla de columnas usario (``userId``), item (``show_id``,``title``) y voto (``score``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_movies_and_ratings_fc_model(df_list):\n",
    "    # Union del tipo left de movies_v1 con ratings_v1\n",
    "    df_merged = pd.merge(df_list['movies_v1'][['show_id','title']], df_list['ratings_v1'][['movieId','score','userId']], left_on=\"show_id\", right_on=\"movieId\", how=\"inner\")\n",
    "    # Resetear la numeracion de los índices\n",
    "    df_merged = df_merged.reset_index(drop=True)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_model_df = merge_movies_and_ratings_fc_model(parquet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 18189 registros nulos donde el mismo usuario ha calificado con una puntuación a la misma película o serie\n"
     ]
    }
   ],
   "source": [
    "# Verifiquemos los registros duplicados\n",
    "duplicated_records_fc_model = fc_model_df.duplicated().sum()\n",
    "print(f\"Hay {duplicated_records_fc_model} registros nulos donde el mismo usuario ha calificado con una puntuación a la misma película o serie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover los registros duplicados\n",
    "fc_model_df = fc_model_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportación de la data\n",
    "def save_as_parquet_fc_model(df: pd.DataFrame, file_name: str):\n",
    "    data_proc_dir = path.make_dir_function(\"dataset\")\n",
    "    file_path = data_proc_dir(file_name)\n",
    "    df.to_parquet(f\"{file_path}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportando la data que será consumido por el modelo de Sistema de Recomendación Basado en el Filtro Colaborativo\n",
    "save_as_parquet_fc_model(fc_model_df,\"fc_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2f4b7f2e86741d0e2392e8225a1745822d18916a96afaca630d13c14301b376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
